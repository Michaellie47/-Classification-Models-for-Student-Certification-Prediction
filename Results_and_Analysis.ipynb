{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization\n",
    "- Accuracy Tables: Detailed model performance tables for both training and validation accuracy.\n",
    "- Final Plots: Accuracy comparison between Logistic Regression and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -Checking Accuracies tables-\n",
    "print(accuracies_table_1)\n",
    "print(accuracies_table_2)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Logistic Regression Plot\n",
    "axs[0].plot(accuracies_table_1['l2_penalty'], accuracies_table_1['train_accuracy'], color='red', label='Train Accuracy')\n",
    "axs[0].plot(accuracies_table_1['l2_penalty'], accuracies_table_1['validation_accuracy'], color='blue', linestyle='--', label='Validation Accuracy')\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_ylim(0.75, 1.0)\n",
    "axs[0].set_title('Logistic Regression Accuracy')\n",
    "axs[0].set_xlabel('L2 Penalty (Log Scale)')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# KNN Plot\n",
    "axs[1].plot(accuracies_table_2['n_neighbors'], accuracies_table_2['train_accuracy'], color='green', label='Train Accuracy')\n",
    "axs[1].plot(accuracies_table_2['n_neighbors'], accuracies_table_2['validation_accuracy'], color='purple', linestyle='--', label='Validation Accuracy')\n",
    "axs[1].set_xlim(3, 27)\n",
    "axs[1].set_ylim(0.75, 1.0)\n",
    "axs[1].set_title('KNN Accuracy')\n",
    "axs[1].set_xlabel('Number of Neighbors')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I developed and evaluated two classification models — Logistic Regression and K-Nearest Neighbors (KNN) — each optimized with multiple hyperparameters to predict outcomes based on a provided dataset. For Logistic Regression, I experimented with six levels of L2 regularization (penalties of 0.001, 0.01, 0.1, 1, 10, and 100), while for KNN, I evaluated model performance across five different neighbor counts (5, 10, 15, 20, and 25).\n",
    "\n",
    "Initially, using the raw data with no pre-processing, the baseline model accuracy was 0.51642, which indicated significant room for improvement. To enhance model performance, I implemented a comprehensive pre-processing pipeline. This included handling missing values by imputing the mean for NaN entries and encoding categorical variables using one-hot encoding to convert them into a numerical format. I also excluded the `userid_DI` feature, focusing on the most informative features for training.\n",
    "\n",
    "Post pre-processing, I trained and validated both models, observing how accuracy varied with different hyperparameters. In the case of Logistic Regression, a smaller L2 regularization penalty yielded higher validation accuracy, indicating a stronger model fit with lower regularization (i.e., larger values of the regularization parameter `C`). For KNN, the impact of the neighbor count on validation accuracy was less predictable, with accuracy levels fluctuating as the number of neighbors increased.\n",
    "\n",
    "Ultimately, Logistic Regression emerged as the superior model, consistently achieving the highest validation accuracy across hyperparameter settings. This model met the project’s target requirement, reaching a validation accuracy of 0.95 or higher. By carefully selecting and tuning hyperparameters and applying robust pre-processing techniques, I successfully enhanced model performance and met the assignment's criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethical Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project raises several important ethical implications, particularly concerning the potential use of a predictive model aimed at maximizing revenue by encouraging students to complete a paid certification program. Such a focus on profit could lead to ethical challenges, including data bias, risks to the platform’s credibility, and potential discrimination.\n",
    "\n",
    "Firstly, the use of predictive models with a primary profit-driven motive risks embedding historical bias into decision-making. Historical bias arises when data reflects past inequities or societal biases, often related to certain demographics. Even if the data is accurate and well-sampled, it can still carry harmful biases that perpetuate inequalities. In this case, the model might inadvertently favor students who already have better access to education, thereby reinforcing existing disparities rather than providing equitable opportunities.\n",
    "\n",
    "Secondly, prioritizing profit over ethical considerations could undermine the credibility and integrity of the online education platform. Users may perceive the platform as focused solely on revenue rather than on promoting fair access to education. To maintain trust, the platform should prioritize values such as fairness, transparency, and ethical development in deploying predictive models. This would demonstrate a commitment to using data-driven insights responsibly to support all learners equitably.\n",
    "\n",
    "In conclusion, implementing predictive modeling in this context requires careful consideration of ethical principles to avoid perpetuating discrimination, ensure transparency, and uphold the platform’s reputation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
